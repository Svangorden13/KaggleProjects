{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T17:13:47.511744Z","iopub.execute_input":"2023-09-14T17:13:47.512262Z","iopub.status.idle":"2023-09-14T17:13:57.364669Z","shell.execute_reply.started":"2023-09-14T17:13:47.512221Z","shell.execute_reply":"2023-09-14T17:13:57.363507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE=10000\nBATCH_SIZE=32\nIMG_SIZE=(32,32)\n\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory('/kaggle/input',\n                                                                 validation_split=.9,\n                                                                 subset='training',\n                                                                 seed=123,\n                                                                 image_size=IMG_SIZE,\n                                                                 batch_size=BATCH_SIZE,\n                                                                 shuffle=True)\nval_data = tf.keras.preprocessing.image_dataset_from_directory('/kaggle/input',\n                                                               validation_split=.9,\n                                                               subset='validation',\n                                                               seed=123,\n                                                               image_size=IMG_SIZE,\n                                                               batch_size=BATCH_SIZE)\n\n#train_data = train_data.map(lambda img, lab: tf.image.resize(img, IMG_SIZE))\n#val_data = val_data.map(lambda img, lab: tf.image.resize(img, IMG_SIZE))\n\n#train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n#val_data = val_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T17:13:57.366767Z","iopub.execute_input":"2023-09-14T17:13:57.367510Z","iopub.status.idle":"2023-09-14T17:14:40.707015Z","shell.execute_reply.started":"2023-09-14T17:13:57.367474Z","shell.execute_reply":"2023-09-14T17:14:40.705706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir = '/kaggle/input/gananime-lite/'\n[os.path.join(image_dir, filename) for filename in os.listdir(image_dir)]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T17:29:24.987547Z","iopub.execute_input":"2023-09-14T17:29:24.987941Z","iopub.status.idle":"2023-09-14T17:29:25.006966Z","shell.execute_reply.started":"2023-09-14T17:29:24.987909Z","shell.execute_reply":"2023-09-14T17:29:25.005271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = '/kaggle/input/gananime-lite/out2/seed1000.png'\n\ndef load_and_decode_image(file_path):\n    # Read the image from file\n    image = tf.io.read_file(file_path)\n    # Decode the image (adjust this according to your image format)\n    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n    # You may also want to normalize and resize the image here\n    image = tf.image.resize(image, IMG_SIZE)\n    image = (image - 127.5) / 127.5  # Normalize to [-1, 1]\n    return image\n\nimage_paths_tensor = tf.constant([image_paths])\ndataset = tf.data.Dataset.from_tensor_slices(image_paths_tensor)\ndataset = dataset.map(load_and_decode_image)\ndataset = tf.data.Dataset.zip((dataset, tf.data.Dataset.from_tensor_slices([1])))\ntrain_data = dataset.repeat(10000).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:24:41.307781Z","iopub.execute_input":"2023-09-14T18:24:41.308232Z","iopub.status.idle":"2023-09-14T18:24:41.468355Z","shell.execute_reply.started":"2023-09-14T18:24:41.308186Z","shell.execute_reply":"2023-09-14T18:24:41.467394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,10))\nfor img, lab in train_data.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        currimg = img[i]\n        currimg = currimg*127.5+127.5\n        plt.imshow(currimg.numpy().astype('uint8'))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:29:48.264387Z","iopub.execute_input":"2023-09-14T18:29:48.264812Z","iopub.status.idle":"2023-09-14T18:29:50.348862Z","shell.execute_reply.started":"2023-09-14T18:29:48.264778Z","shell.execute_reply":"2023-09-14T18:29:50.347610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndef make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(4*4*256, use_bias=False, input_shape=(100,)))\n    #model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((4, 4, 256)))\n    assert model.output_shape == (None, 4, 4, 256)  # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 8, 8, 128)\n    #model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 16, 16, 128)\n    #model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 32, 32, 128)\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2D(3, (3,3), activation='tanh', padding='same'))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:29:58.649120Z","iopub.execute_input":"2023-09-14T18:29:58.649551Z","iopub.status.idle":"2023-09-14T18:29:58.662693Z","shell.execute_reply.started":"2023-09-14T18:29:58.649518Z","shell.execute_reply":"2023-09-14T18:29:58.661456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()\nnoise = tf.random.normal([1,100])\ngen_img = generator(noise, training=False)\nplt.imshow(gen_img[0]*127.5)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:00.056392Z","iopub.execute_input":"2023-09-14T18:30:00.056849Z","iopub.status.idle":"2023-09-14T18:30:00.503453Z","shell.execute_reply.started":"2023-09-14T18:30:00.056812Z","shell.execute_reply":"2023-09-14T18:30:00.502229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[32, 32, 3]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:01.803934Z","iopub.execute_input":"2023-09-14T18:30:01.804373Z","iopub.status.idle":"2023-09-14T18:30:01.814069Z","shell.execute_reply.started":"2023-09-14T18:30:01.804338Z","shell.execute_reply":"2023-09-14T18:30:01.812269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(gen_img)\nprint(decision)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:03.205129Z","iopub.execute_input":"2023-09-14T18:30:03.205607Z","iopub.status.idle":"2023-09-14T18:30:03.284819Z","shell.execute_reply.started":"2023-09-14T18:30:03.205565Z","shell.execute_reply":"2023-09-14T18:30:03.283448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n    return real_loss + fake_loss\n\ndef generator_loss(fake_output):\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)\n\ngen_opt = tf.keras.optimizers.Adam(1e-4)\ndisc_opt = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:04.533353Z","iopub.execute_input":"2023-09-14T18:30:04.534175Z","iopub.status.idle":"2023-09-14T18:30:04.548552Z","shell.execute_reply.started":"2023-09-14T18:30:04.534110Z","shell.execute_reply":"2023-09-14T18:30:04.547262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = '/kaggle/working/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=gen_opt,\n                                 discriminator_optimizer=disc_opt,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:05.977509Z","iopub.execute_input":"2023-09-14T18:30:05.977912Z","iopub.status.idle":"2023-09-14T18:30:05.985337Z","shell.execute_reply.started":"2023-09-14T18:30:05.977881Z","shell.execute_reply":"2023-09-14T18:30:05.983955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS=10\nnoise_dim=100\nnum_examples=4\n\nseed = tf.random.normal([num_examples, noise_dim])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:39.501934Z","iopub.execute_input":"2023-09-14T18:30:39.502383Z","iopub.status.idle":"2023-09-14T18:30:39.509688Z","shell.execute_reply.started":"2023-09-14T18:30:39.502347Z","shell.execute_reply":"2023-09-14T18:30:39.508557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        gen_imgs = generator(noise, training=True)\n        \n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(gen_imgs, training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n        \n    gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    \n    gen_opt.apply_gradients(zip(gen_grads, generator.trainable_variables))\n    disc_opt.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:41.601770Z","iopub.execute_input":"2023-09-14T18:30:41.602205Z","iopub.status.idle":"2023-09-14T18:30:41.611736Z","shell.execute_reply.started":"2023-09-14T18:30:41.602139Z","shell.execute_reply":"2023-09-14T18:30:41.610433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom IPython import display\n\ndef train(dataset, epochs):\n    num_batches = dataset.cardinality().numpy()\n    \n    for epoch in range(epochs):\n        print(\"EPOCH \", epoch)\n        \n        for image_batch, labs in tqdm(dataset):\n            train_step(image_batch)\n            \n        # Produce images for the GIF as you go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n            \n        if (epoch+1) % 2 == 0:\n            checkpoint.save(file_prefix=checkpoint_prefix)\n            \n    # Generate after the final epoch\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                           epochs,\n                           seed)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:42.712606Z","iopub.execute_input":"2023-09-14T18:30:42.713809Z","iopub.status.idle":"2023-09-14T18:30:42.723183Z","shell.execute_reply.started":"2023-09-14T18:30:42.713753Z","shell.execute_reply":"2023-09-14T18:30:42.722307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(2, 2))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 2, i+1)\n        plt.imshow(predictions[i, :, :, :] * 127.5 + 127.5)\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:43.826898Z","iopub.execute_input":"2023-09-14T18:30:43.827331Z","iopub.status.idle":"2023-09-14T18:30:43.835267Z","shell.execute_reply.started":"2023-09-14T18:30:43.827295Z","shell.execute_reply":"2023-09-14T18:30:43.834217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_data, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T18:30:45.235510Z","iopub.execute_input":"2023-09-14T18:30:45.235949Z","iopub.status.idle":"2023-09-14T19:03:19.194908Z","shell.execute_reply.started":"2023-09-14T18:30:45.235912Z","shell.execute_reply":"2023-09-14T19:03:19.193257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = tf.random.normal([1,100])\ngen_img = generator(noise, training=False)\nplt.imshow(gen_img[0,:,:,:])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T19:05:39.879548Z","iopub.execute_input":"2023-09-14T19:05:39.879983Z","iopub.status.idle":"2023-09-14T19:05:40.195557Z","shell.execute_reply.started":"2023-09-14T19:05:39.879952Z","shell.execute_reply":"2023-09-14T19:05:40.194395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}